{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0adad57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-28 15:33:41.732337: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-28 15:33:43.259943: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-28 15:33:45.474614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-28 15:33:45.475734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2021-07-28 15:33:45.475822: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-28 15:33:45.537978: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-28 15:33:45.572809: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-28 15:33:45.586944: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-28 15:33:45.629654: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-07-28 15:33:45.646896: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-28 15:33:45.652563: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-28 15:33:45.652806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-28 15:33:45.653678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-28 15:33:45.654382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d2eeb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_3353/1150452805.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-28 15:33:45.693360: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2299995000 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-28 15:33:45.694439: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5603394c3cf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-07-28 15:33:45.694465: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-07-28 15:33:45.940685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-28 15:33:45.941632: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56033b030760 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-07-28 15:33:45.941662: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2021-07-28 15:33:45.943270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-28 15:33:45.944130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2021-07-28 15:33:45.944204: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-28 15:33:45.944239: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-28 15:33:45.944280: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-28 15:33:45.944305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-28 15:33:45.944329: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-07-28 15:33:45.944369: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-28 15:33:45.944403: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-28 15:33:45.944502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-28 15:33:45.945254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-28 15:33:45.945929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2021-07-28 15:33:45.947568: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-28 15:33:49.462954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-28 15:33:49.463012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2021-07-28 15:33:49.463030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2021-07-28 15:33:49.466711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-28 15:33:49.467565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-28 15:33:49.468358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/device:GPU:0 with 10638 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n"
     ]
    }
   ],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "701587bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efab1f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-28 15:33:49.496335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-28 15:33:49.497141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2021-07-28 15:33:49.497230: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-28 15:33:49.497270: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-28 15:33:49.497322: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-28 15:33:49.497373: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-28 15:33:49.497419: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-07-28 15:33:49.497452: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-28 15:33:49.497481: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-28 15:33:49.497564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-28 15:33:49.498332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-28 15:33:49.499110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2021-07-28 15:33:49.499153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-28 15:33:49.499162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2021-07-28 15:33:49.499169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2021-07-28 15:33:49.499295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-28 15:33:49.500078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-28 15:33:49.500835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10638 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a6a8a0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: segmentation-models in /opt/conda/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: efficientnet==1.0.0 in /opt/conda/lib/python3.7/site-packages (from segmentation-models) (1.0.0)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from segmentation-models) (1.0.8)\n",
      "Requirement already satisfied: image-classifiers==1.0.0 in /opt/conda/lib/python3.7/site-packages (from segmentation-models) (1.0.0)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.0.0->segmentation-models) (0.18.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.19.5)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (2.10.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.16.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2021.7.2)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.9.0)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.7.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (8.3.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.4.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation-models) (5.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install segmentation-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "63e653b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "import segmentation_models as sm\n",
    "sm.set_framework('tf.keras')\n",
    "sm.framework()\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9f1ef634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import conv_utils\n",
    "from keras.backend import normalize_data_format\n",
    "keras.backend.set_image_data_format('channels_last')\n",
    "from keras.metrics import MeanIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b78894c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                    img_process.ipynb  test_run2.ipynb\n",
      "_image_classification.ipynb  test_run.ipynb     transfer_learning.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1096389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "!unzip '/home/jupyter/prpls-dl/sub_reg_train128.zip' -d '/tmp'\n",
    "!unzip '/home/jupyter/prpls-dl/sub_reg_label128.zip' -d '/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca218d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 8512\n",
      "Number of label images: 8512\n"
     ]
    }
   ],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "\n",
    "train_dirpath= '/tmp/sub_reg_train128'\n",
    "print('Number of training images:', len(fnmatch.filter(os.listdir(train_dirpath), '*.tif')))\n",
    "\n",
    "label_dirpath= '/tmp/sub_reg_label128'\n",
    "print('Number of label images:', len(fnmatch.filter(os.listdir(label_dirpath), '*.tif')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "902acd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list=os.listdir('/tmp/sub_reg_train128')\n",
    "mask_list=os.listdir('/tmp/sub_reg_label128')\n",
    "mask = []\n",
    "img = []\n",
    "for filename in train_list:\n",
    "    if filename.endswith('/tmp/sub_reg_train128/*.tif'):\n",
    "        img.append(filename)\n",
    "\n",
    "for filename in mask_list:\n",
    "    if filename.endswith('/tmp/sub_reg_label128/*.tif'):\n",
    "        mask.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ba2105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.sort()\n",
    "mask.sort()\n",
    "img = img[:8512]\n",
    "masks = mask[:8512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18b76d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((8512, 128, 128), dtype=np.float32)\n",
    "X = np.zeros((8512, 128, 128, 3), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5891d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in img:\n",
    "    index = img.index(i)\n",
    "    dir_img = os.path.join(train_dirpath, i)\n",
    "    img = Image.open(dir_img)\n",
    "    X = img.append(img)\n",
    "    \n",
    "X = np.array(X)\n",
    "    \n",
    "for file in masks:\n",
    "    dir_mask = os.path.join(label_dirpath, mask)\n",
    "    mask_img = cv2.imread(dir_mask)\n",
    "    mask_img = (mask!=2)*1.0\n",
    "    mask_img = cv2.resize(mask, (128, 128))\n",
    "    mask_img = 1.0*(mask[:,:,0]>0.2)\n",
    "    y = mask.append(mask_img)\n",
    "    \n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ad4c12dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8512, 128, 128, 3)\n",
      "(8512, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "24cd2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=0)\n",
    "\n",
    "BACKBONE = 'resnet34'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "X_train = preprocess_input(X_train)\n",
    "X_test = preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0aae5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "import segmentation_models as sm\n",
    "sm.set_framework('tf.keras')\n",
    "sm.framework()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Reshape\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d209bf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class values in the dataset are ...  [0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Class values in the dataset are ... \", np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "45ef914e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class values in the dataset are ...  [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "n_classes=2\n",
    "train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n",
    "y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))\n",
    "\n",
    "test_masks_cat = to_categorical(y_test, num_classes=n_classes)\n",
    "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))\n",
    "print(\"Class values in the dataset are ... \", np.unique(y_train_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "44c9cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "import segmentation_models as sm\n",
    "sm.set_framework('tf.keras')\n",
    "sm.framework()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from keras.layers import Reshape\n",
    "N = X_train.shape[-1]\n",
    "\n",
    "model = sm.Unet(backbone_name='resnet34', encoder_weights=None, input_shape=(None, None, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b3a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.7346 - iou_score: 0.2655WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0133s vs `on_test_batch_end` time: 0.0764s). Check your callbacks.\n",
      "200/200 [==============================] - 66s 328ms/step - loss: 0.7346 - iou_score: 0.2655 - val_loss: 0.7191 - val_iou_score: 0.2809\n",
      "Epoch 2/30\n",
      "200/200 [==============================] - 64s 321ms/step - loss: 0.7044 - iou_score: 0.2956 - val_loss: 0.6899 - val_iou_score: 0.3101\n",
      "Epoch 3/30\n",
      " 19/200 [=>............................] - ETA: 51s - loss: 0.6887 - iou_score: 0.3113"
     ]
    }
   ],
   "source": [
    "# def dice_coefficient(y_true, y_pred):\n",
    "#     numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "#     denominator = tf.reduce_sum(y_true + y_pred)\n",
    "#     return numerator / (denominator + tf.keras.backend.epsilon())\n",
    "\n",
    "# def loss(y_true, y_pred):\n",
    "#     return binary_crossentropy(y_true, y_pred) - tf.math.log(dice_coefficient(y_true, y_pred) + tf.keras.backend.epsilon())\n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "model.compile(optimizer='sgd', loss=sm.losses.JaccardLoss(), metrics=sm.metrics.IOUScore())\n",
    "model.fit(X_train,y_train_cat,batch_size=32,epochs=30,validation_data=(X_test, y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a6ec589",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation='softmax'\n",
    "\n",
    "\n",
    "LR = 0.0001\n",
    "optim = keras.optimizers.Adam(LR)\n",
    "\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "# set class weights for dice_loss (car: 1.; pedestrian: 2.; background: 0.5;)\n",
    "dice_loss = sm.losses.DiceLoss(class_weights=np.array([1., 2., 0.5])) \n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
    "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0696c37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, None, None, 6 1792        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, None, None, 6 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, None, None, 6 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, None, None, 1 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, None, None, 1 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, None, None, 2 295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, None, None, 2 590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, None, None, 2 590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, None, None, 2 590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, None, None, 5 1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, None, None, 5 2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, None, None, 5 2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, None, None, 5 2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, None, None, 5 0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, None, None, 5 2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, None, None, 5 2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, None, None, 5 2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, None, None, 5 2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, None, None, 5 0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_block1_conv (Conv2D)     (None, None, None, 5 2359296     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_block1_bn (BatchNormaliz (None, None, None, 5 2048        center_block1_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_block1_relu (Activation) (None, None, None, 5 0           center_block1_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "center_block2_conv (Conv2D)     (None, None, None, 5 2359296     center_block1_relu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_block2_bn (BatchNormaliz (None, None, None, 5 2048        center_block2_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_block2_relu (Activation) (None, None, None, 5 0           center_block2_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_upsampling (UpSa (None, None, None, 5 0           center_block2_relu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_concat (Concaten (None, None, None, 1 0           decoder_stage0_upsampling[0][0]  \n",
      "                                                                 block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_conv (Conv2D)   (None, None, None, 2 2359296     decoder_stage0_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_relu (Activatio (None, None, None, 2 0           decoder_stage0a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_conv (Conv2D)   (None, None, None, 2 589824      decoder_stage0a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_relu (Activatio (None, None, None, 2 0           decoder_stage0b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_upsampling (UpSa (None, None, None, 2 0           decoder_stage0b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_concat (Concaten (None, None, None, 7 0           decoder_stage1_upsampling[0][0]  \n",
      "                                                                 block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_conv (Conv2D)   (None, None, None, 1 884736      decoder_stage1_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_bn (BatchNormal (None, None, None, 1 512         decoder_stage1a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_relu (Activatio (None, None, None, 1 0           decoder_stage1a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_conv (Conv2D)   (None, None, None, 1 147456      decoder_stage1a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_bn (BatchNormal (None, None, None, 1 512         decoder_stage1b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_relu (Activatio (None, None, None, 1 0           decoder_stage1b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_upsampling (UpSa (None, None, None, 1 0           decoder_stage1b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_concat (Concaten (None, None, None, 3 0           decoder_stage2_upsampling[0][0]  \n",
      "                                                                 block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_conv (Conv2D)   (None, None, None, 6 221184      decoder_stage2_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_bn (BatchNormal (None, None, None, 6 256         decoder_stage2a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_relu (Activatio (None, None, None, 6 0           decoder_stage2a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_conv (Conv2D)   (None, None, None, 6 36864       decoder_stage2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_bn (BatchNormal (None, None, None, 6 256         decoder_stage2b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_relu (Activatio (None, None, None, 6 0           decoder_stage2b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_upsampling (UpSa (None, None, None, 6 0           decoder_stage2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_concat (Concaten (None, None, None, 1 0           decoder_stage3_upsampling[0][0]  \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_conv (Conv2D)   (None, None, None, 3 55296       decoder_stage3_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_bn (BatchNormal (None, None, None, 3 128         decoder_stage3a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_relu (Activatio (None, None, None, 3 0           decoder_stage3a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_conv (Conv2D)   (None, None, None, 3 9216        decoder_stage3a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_bn (BatchNormal (None, None, None, 3 128         decoder_stage3b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_relu (Activatio (None, None, None, 3 0           decoder_stage3b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_upsampling (UpSa (None, None, None, 3 0           decoder_stage3b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_conv (Conv2D)   (None, None, None, 1 4608        decoder_stage4_upsampling[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_bn (BatchNormal (None, None, None, 1 64          decoder_stage4a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_relu (Activatio (None, None, None, 1 0           decoder_stage4a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_conv (Conv2D)   (None, None, None, 1 2304        decoder_stage4a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_bn (BatchNormal (None, None, None, 1 64          decoder_stage4b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_relu (Activatio (None, None, None, 1 0           decoder_stage4b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv2D)             (None, None, None, 4 580         decoder_stage4b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, None, None, 4 0           final_conv[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 29,062,404\n",
      "Trainable params: 29,058,372\n",
      "Non-trainable params: 4,032\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Start Time for Model 1-Resnet: 2021-07-23 21:04:48.884298\n",
      "Epoch 1/100\n",
      "  2/200 [..............................] - ETA: 1:21 - loss: 0.9156 - iou_score: 0.0844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1714s vs `on_train_batch_end` time: 0.3040s). Check your callbacks.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8122 - iou_score: 0.1879WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0110s vs `on_test_batch_end` time: 0.1320s). Check your callbacks.\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 0.8122 - iou_score: 0.1879 - val_loss: 0.7787 - val_iou_score: 0.2212\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 0.7679 - iou_score: 0.2322 - val_loss: 0.7776 - val_iou_score: 0.2224\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 0.7613 - iou_score: 0.2388 - val_loss: 0.7903 - val_iou_score: 0.2096\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 0.7595 - iou_score: 0.2405 - val_loss: 0.7735 - val_iou_score: 0.2265\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 0.7586 - iou_score: 0.2414 - val_loss: 0.7606 - val_iou_score: 0.2394\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 0.7583 - iou_score: 0.2418 - val_loss: 0.7633 - val_iou_score: 0.2367\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 0.7580 - iou_score: 0.2420 - val_loss: 0.7685 - val_iou_score: 0.2315\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 0.7578 - iou_score: 0.2423 - val_loss: 0.7602 - val_iou_score: 0.2398\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 0.7577 - iou_score: 0.2423 - val_loss: 0.7856 - val_iou_score: 0.2144\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 0.7576 - iou_score: 0.2424 - val_loss: 0.7607 - val_iou_score: 0.2393\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 0.7575 - iou_score: 0.2425 - val_loss: 0.7585 - val_iou_score: 0.2414\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 0.7575 - iou_score: 0.2425 - val_loss: 0.7718 - val_iou_score: 0.2282\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 0.7574 - iou_score: 0.2426 - val_loss: 0.7593 - val_iou_score: 0.2406\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 0.7575 - iou_score: 0.2425 - val_loss: 0.7582 - val_iou_score: 0.2417\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 0.7574 - iou_score: 0.2426 - val_loss: 0.7647 - val_iou_score: 0.2352\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 0.7573 - iou_score: 0.2426 - val_loss: 0.7660 - val_iou_score: 0.2340\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 105s 526ms/step - loss: 0.7574 - iou_score: 0.2426 - val_loss: 0.7608 - val_iou_score: 0.2391\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 105s 526ms/step - loss: 0.7574 - iou_score: 0.2426 - val_loss: 0.7580 - val_iou_score: 0.2420\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 105s 526ms/step - loss: 0.7575 - iou_score: 0.2425 - val_loss: 0.7595 - val_iou_score: 0.2405\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 0.7573 - iou_score: 0.2427 - val_loss: 0.7649 - val_iou_score: 0.2350\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 105s 524ms/step - loss: 0.7573 - iou_score: 0.2427 - val_loss: 0.7580 - val_iou_score: 0.2419\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 105s 524ms/step - loss: 0.7572 - iou_score: 0.2429 - val_loss: 0.7604 - val_iou_score: 0.2395\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 105s 524ms/step - loss: 0.7573 - iou_score: 0.2426 - val_loss: 0.7580 - val_iou_score: 0.2419\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 105s 524ms/step - loss: 0.7572 - iou_score: 0.2428 - val_loss: 0.7630 - val_iou_score: 0.2369\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 105s 524ms/step - loss: 0.7573 - iou_score: 0.2427 - val_loss: 0.7615 - val_iou_score: 0.2384\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7573 - iou_score: 0.2427 - val_loss: 0.7591 - val_iou_score: 0.2408\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 105s 524ms/step - loss: 0.7572 - iou_score: 0.2429 - val_loss: 0.7588 - val_iou_score: 0.2411\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7583 - val_iou_score: 0.2416\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7581 - val_iou_score: 0.2419\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7580 - val_iou_score: 0.2420\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7580 - val_iou_score: 0.2420\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7573 - iou_score: 0.2427 - val_loss: 0.7637 - val_iou_score: 0.2362\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 105s 524ms/step - loss: 0.7572 - iou_score: 0.2428 - val_loss: 0.7585 - val_iou_score: 0.2414\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 105s 524ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7585 - val_iou_score: 0.2414\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7588 - val_iou_score: 0.2412\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7572 - iou_score: 0.2428 - val_loss: 0.7579 - val_iou_score: 0.2421\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7572 - iou_score: 0.2428 - val_loss: 0.7579 - val_iou_score: 0.2420\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7618 - val_iou_score: 0.2382\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7633 - val_iou_score: 0.2367\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7572 - iou_score: 0.2428 - val_loss: 0.7579 - val_iou_score: 0.2420\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7571 - iou_score: 0.2428 - val_loss: 0.7579 - val_iou_score: 0.2420\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7572 - iou_score: 0.2428 - val_loss: 0.7579 - val_iou_score: 0.2420\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7572 - iou_score: 0.2428 - val_loss: 0.7579 - val_iou_score: 0.2420\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7579 - val_iou_score: 0.2421\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7579 - val_iou_score: 0.2421\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7633 - val_iou_score: 0.2367\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7573 - iou_score: 0.2427 - val_loss: 0.7580 - val_iou_score: 0.2419\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7583 - val_iou_score: 0.2416\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7583 - val_iou_score: 0.2417\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 104s 522ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7579 - val_iou_score: 0.2420\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7571 - iou_score: 0.2428 - val_loss: 0.7579 - val_iou_score: 0.2420\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7570 - iou_score: 0.2430 - val_loss: 0.7649 - val_iou_score: 0.2350\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7572 - iou_score: 0.2428 - val_loss: 0.7581 - val_iou_score: 0.2419\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 104s 522ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7583 - val_iou_score: 0.2416\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7570 - iou_score: 0.2430 - val_loss: 0.7593 - val_iou_score: 0.2406\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7570 - iou_score: 0.2430 - val_loss: 0.7607 - val_iou_score: 0.2392\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7591 - val_iou_score: 0.2408\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7572 - iou_score: 0.2428 - val_loss: 0.7579 - val_iou_score: 0.2421\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 104s 522ms/step - loss: 0.7572 - iou_score: 0.2428 - val_loss: 0.7579 - val_iou_score: 0.2421\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 104s 522ms/step - loss: 0.7571 - iou_score: 0.2429 - val_loss: 0.7579 - val_iou_score: 0.2421\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.7571 - iou_score: 0.2430 - val_loss: 0.7582 - val_iou_score: 0.2417\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 104s 522ms/step - loss: 0.5260 - iou_score: 0.4746 - val_loss: 0.4411 - val_iou_score: 0.5597\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 104s 522ms/step - loss: 0.3846 - iou_score: 0.6160 - val_loss: 0.4188 - val_iou_score: 0.5820\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3794 - iou_score: 0.6208 - val_loss: 0.5570 - val_iou_score: 0.4432\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 0.3769 - iou_score: 0.6234 - val_loss: 0.3697 - val_iou_score: 0.6310\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 0.3821 - iou_score: 0.6176 - val_loss: 0.3683 - val_iou_score: 0.6325\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 0.3736 - iou_score: 0.6267 - val_loss: 0.3681 - val_iou_score: 0.6327\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 0.3713 - iou_score: 0.6290 - val_loss: 0.3679 - val_iou_score: 0.6328\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 0.3829 - iou_score: 0.6181 - val_loss: 0.3678 - val_iou_score: 0.6329\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 0.3797 - iou_score: 0.6206 - val_loss: 0.3678 - val_iou_score: 0.6330\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 0.3722 - iou_score: 0.6281 - val_loss: 0.3677 - val_iou_score: 0.6330\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3796 - iou_score: 0.6207 - val_loss: 0.3677 - val_iou_score: 0.6330\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 0.3727 - iou_score: 0.6269 - val_loss: 0.3677 - val_iou_score: 0.6331\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 0.3827 - iou_score: 0.6170 - val_loss: 0.3677 - val_iou_score: 0.6331\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3677 - iou_score: 0.6320 - val_loss: 0.3677 - val_iou_score: 0.6331\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 0.3877 - iou_score: 0.6120 - val_loss: 0.3677 - val_iou_score: 0.6331\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3714 - iou_score: 0.6282 - val_loss: 0.3676 - val_iou_score: 0.6331\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 0.3795 - iou_score: 0.6208 - val_loss: 0.3676 - val_iou_score: 0.6331\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 0.3695 - iou_score: 0.6308 - val_loss: 0.3676 - val_iou_score: 0.6331\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3714 - iou_score: 0.6283 - val_loss: 0.3676 - val_iou_score: 0.6331\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3645 - iou_score: 0.6358 - val_loss: 0.3676 - val_iou_score: 0.6331\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3807 - iou_score: 0.6196 - val_loss: 0.3676 - val_iou_score: 0.6331\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3770 - iou_score: 0.6233 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3820 - iou_score: 0.6183 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3814 - iou_score: 0.6196 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3914 - iou_score: 0.6096 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3876 - iou_score: 0.6134 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3857 - iou_score: 0.6146 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3782 - iou_score: 0.6221 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3788 - iou_score: 0.6221 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3788 - iou_score: 0.6221 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3801 - iou_score: 0.6209 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3882 - iou_score: 0.6121 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3832 - iou_score: 0.6171 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3757 - iou_score: 0.6246 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3701 - iou_score: 0.6309 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3738 - iou_score: 0.6258 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3782 - iou_score: 0.6221 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 0.3776 - iou_score: 0.6234 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 0.3870 - iou_score: 0.6134 - val_loss: 0.3676 - val_iou_score: 0.6332\n",
      "End Time for Model 1-Resnet: 2021-07-23 23:59:32.744378\n",
      "Duration for Model 1-Resnet: 2:54:43.860080\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D\n",
    "from keras.models import Model\n",
    "\n",
    "from tensorflow.keras.utils import get_file\n",
    "###Model 1\n",
    "BACKBONE1 =  'vgg19'\n",
    "preprocess_input1 = sm.get_preprocessing(BACKBONE1)\n",
    "\n",
    "# preprocess input\n",
    "X_train1 = preprocess_input1(X_train)\n",
    "X_test1 = preprocess_input1(X_test)\n",
    "\n",
    "random_state=0\n",
    "# define model\n",
    "model1 = sm.Unet(BACKBONE1, encoder_weights=None, classes=n_classes, activation=activation)\n",
    "\n",
    "# compile keras model with defined optimizer, loss and metrics\n",
    "model1.compile(optimizer=optim, loss=sm.losses.JaccardLoss(), metrics=sm.metrics.IOUScore())\n",
    "print(model1.summary())\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "start_time_resnet = datetime.now()\n",
    "print('Start Time for Model 1-Resnet: {}'.format(start_time_resnet))\n",
    "\n",
    "\n",
    "history1=model1.fit(X_train1, \n",
    "          y_train_cat,\n",
    "          batch_size=32, \n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test1, y_test_cat))\n",
    "\n",
    "end_time_resnet = datetime.now()\n",
    "print('End Time for Model 1-Resnet: {}'.format(end_time_resnet))\n",
    "print('Duration for Model 1-Resnet: {}'.format(end_time_resnet - start_time_resnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47579e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-24 01:19:46.748837: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vgg19_backbone_100epochs2.tf/assets\n"
     ]
    }
   ],
   "source": [
    "model1.save('vgg19_backbone_100epochs2.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3b271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D\n",
    "from keras.models import Model\n",
    "\n",
    "from tensorflow.keras.utils import get_file\n",
    "###Model 1\n",
    "BACKBONE1 =  'vgg19'\n",
    "preprocess_input1 = sm.get_preprocessing(BACKBONE1)\n",
    "\n",
    "# preprocess input\n",
    "X_train1 = preprocess_input1(X_train)\n",
    "X_test1 = preprocess_input1(X_test)\n",
    "\n",
    "# define callbacks for learning rate scheduling and best checkpoints saving\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('./best_model1.h5', save_weights_only=True, save_best_only=True, mode='min'),\n",
    "    keras.callbacks.ReduceLROnPlateau(),\n",
    "]\n",
    "\n",
    "random_state=0\n",
    "# define model\n",
    "model1 = sm.Unet(BACKBONE1, encoder_weights=None, classes=n_classes, activation=activation)\n",
    "\n",
    "# compile keras model with defined optimizer, loss and metrics\n",
    "model1.compile(optimizer=optim, loss=sm.losses.JaccardLoss(), metrics=sm.metrics.IOUScore())\n",
    "print(model1.summary())\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "start_time_resnet = datetime.now()\n",
    "print('Start Time for Model 1-Resnet: {}'.format(start_time_resnet))\n",
    "\n",
    "\n",
    "history1=model1.fit(X_train1, y_train_cat, batch_size=32, \n",
    "                    epochs=200, verbose=1, validation_data=(X_test1, y_test_cat), callbacks=callbacks)\n",
    "\n",
    "end_time_resnet = datetime.now()\n",
    "print('End Time for Model 1-Resnet: {}'.format(end_time_resnet))\n",
    "print('Duration for Model 1-Resnet: {}'.format(end_time_resnet - start_time_resnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadef028",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('vgg19_backbone_1000epochs.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d8a34f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, None, None, 3 9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, None, None, 3 0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, None, None, 6 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, None, None, 6 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, None, None, 6 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, None, None, 6 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, None, None, 6 0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, None, None, 6 256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, None, None, 6 0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, None, None, 6 4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, None, None, 6 0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, None, None, 6 0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn3 (BatchNormaliz (None, None, None, 6 256         stage1_unit1_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu3 (Activation) (None, None, None, 6 0           stage1_unit1_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv3 (Conv2D)     (None, None, None, 2 16384       stage1_unit1_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, None, None, 2 16384       stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, None, 2 0           stage1_unit1_conv3[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, None, None, 2 1024        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, None, None, 2 0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, None, None, 6 16384       stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, None, None, 6 0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, None, None, 6 0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn3 (BatchNormaliz (None, None, None, 6 256         stage1_unit2_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu3 (Activation) (None, None, None, 6 0           stage1_unit2_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv3 (Conv2D)     (None, None, None, 2 16384       stage1_unit2_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 2 0           stage1_unit2_conv3[0][0]         \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, None, None, 2 1024        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, None, None, 2 0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, None, None, 6 16384       stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, None, None, 6 0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, None, None, 6 0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn3 (BatchNormaliz (None, None, None, 6 256         stage1_unit3_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu3 (Activation) (None, None, None, 6 0           stage1_unit3_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv3 (Conv2D)     (None, None, None, 2 16384       stage1_unit3_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 2 0           stage1_unit3_conv3[0][0]         \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, None, None, 2 1024        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, None, None, 2 0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, None, None, 1 32768       stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, None, None, 1 0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, None, None, 1 0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn3 (BatchNormaliz (None, None, None, 1 512         stage2_unit1_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu3 (Activation) (None, None, None, 1 0           stage2_unit1_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv3 (Conv2D)     (None, None, None, 5 65536       stage2_unit1_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, None, None, 5 131072      stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 5 0           stage2_unit1_conv3[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, None, None, 5 2048        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, None, None, 5 0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, None, None, 1 65536       stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, None, None, 1 0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, None, None, 1 0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn3 (BatchNormaliz (None, None, None, 1 512         stage2_unit2_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu3 (Activation) (None, None, None, 1 0           stage2_unit2_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv3 (Conv2D)     (None, None, None, 5 65536       stage2_unit2_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 5 0           stage2_unit2_conv3[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, None, None, 5 2048        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, None, None, 5 0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, None, None, 1 65536       stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, None, None, 1 0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, None, None, 1 0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn3 (BatchNormaliz (None, None, None, 1 512         stage2_unit3_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu3 (Activation) (None, None, None, 1 0           stage2_unit3_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv3 (Conv2D)     (None, None, None, 5 65536       stage2_unit3_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 5 0           stage2_unit3_conv3[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, None, None, 5 2048        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, None, None, 5 0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, None, None, 1 65536       stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, None, None, 1 0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, None, None, 1 0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn3 (BatchNormaliz (None, None, None, 1 512         stage2_unit4_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu3 (Activation) (None, None, None, 1 0           stage2_unit4_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv3 (Conv2D)     (None, None, None, 5 65536       stage2_unit4_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 5 0           stage2_unit4_conv3[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, None, None, 5 2048        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, None, None, 5 0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, None, None, 2 131072      stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, None, None, 2 0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, None, None, 2 0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn3 (BatchNormaliz (None, None, None, 2 1024        stage3_unit1_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu3 (Activation) (None, None, None, 2 0           stage3_unit1_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv3 (Conv2D)     (None, None, None, 1 262144      stage3_unit1_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, None, None, 1 524288      stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 1 0           stage3_unit1_conv3[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, None, None, 1 4096        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, None, None, 1 0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, None, None, 2 262144      stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, None, None, 2 0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, None, None, 2 0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn3 (BatchNormaliz (None, None, None, 2 1024        stage3_unit2_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu3 (Activation) (None, None, None, 2 0           stage3_unit2_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv3 (Conv2D)     (None, None, None, 1 262144      stage3_unit2_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 1 0           stage3_unit2_conv3[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, None, None, 1 4096        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, None, None, 1 0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, None, None, 2 262144      stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, None, None, 2 0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, None, None, 2 0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn3 (BatchNormaliz (None, None, None, 2 1024        stage3_unit3_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu3 (Activation) (None, None, None, 2 0           stage3_unit3_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv3 (Conv2D)     (None, None, None, 1 262144      stage3_unit3_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 1 0           stage3_unit3_conv3[0][0]         \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, None, None, 1 4096        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, None, None, 1 0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, None, None, 2 262144      stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, None, None, 2 0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, None, None, 2 0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn3 (BatchNormaliz (None, None, None, 2 1024        stage3_unit4_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu3 (Activation) (None, None, None, 2 0           stage3_unit4_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv3 (Conv2D)     (None, None, None, 1 262144      stage3_unit4_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 1 0           stage3_unit4_conv3[0][0]         \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, None, None, 1 4096        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, None, None, 1 0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, None, None, 2 262144      stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, None, None, 2 0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, None, None, 2 0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn3 (BatchNormaliz (None, None, None, 2 1024        stage3_unit5_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu3 (Activation) (None, None, None, 2 0           stage3_unit5_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv3 (Conv2D)     (None, None, None, 1 262144      stage3_unit5_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 1 0           stage3_unit5_conv3[0][0]         \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, None, None, 1 4096        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, None, None, 1 0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, None, None, 2 262144      stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, None, None, 2 0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, None, None, 2 0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn3 (BatchNormaliz (None, None, None, 2 1024        stage3_unit6_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu3 (Activation) (None, None, None, 2 0           stage3_unit6_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv3 (Conv2D)     (None, None, None, 1 262144      stage3_unit6_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, None, None, 1 0           stage3_unit6_conv3[0][0]         \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, None, None, 1 4096        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, None, None, 1 0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, None, None, 5 524288      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, None, None, 5 0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, None, None, 5 0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn3 (BatchNormaliz (None, None, None, 5 2048        stage4_unit1_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu3 (Activation) (None, None, None, 5 0           stage4_unit1_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv3 (Conv2D)     (None, None, None, 2 1048576     stage4_unit1_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, None, None, 2 2097152     stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, None, None, 2 0           stage4_unit1_conv3[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, None, None, 2 8192        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, None, None, 2 0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, None, None, 5 1048576     stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, None, None, 5 0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, None, None, 5 0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn3 (BatchNormaliz (None, None, None, 5 2048        stage4_unit2_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu3 (Activation) (None, None, None, 5 0           stage4_unit2_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv3 (Conv2D)     (None, None, None, 2 1048576     stage4_unit2_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, None, None, 2 0           stage4_unit2_conv3[0][0]         \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, None, None, 2 8192        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, None, None, 2 0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, None, None, 5 1048576     stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, None, None, 5 0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, None, None, 5 0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn3 (BatchNormaliz (None, None, None, 5 2048        stage4_unit3_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu3 (Activation) (None, None, None, 5 0           stage4_unit3_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv3 (Conv2D)     (None, None, None, 2 1048576     stage4_unit3_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, None, None, 2 0           stage4_unit3_conv3[0][0]         \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, None, None, 2 8192        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, None, None, 2 0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_upsampling (UpSa (None, None, None, 2 0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_concat (Concaten (None, None, None, 3 0           decoder_stage0_upsampling[0][0]  \n",
      "                                                                 stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_conv (Conv2D)   (None, None, None, 2 7077888     decoder_stage0_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_relu (Activatio (None, None, None, 2 0           decoder_stage0a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_conv (Conv2D)   (None, None, None, 2 589824      decoder_stage0a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_relu (Activatio (None, None, None, 2 0           decoder_stage0b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_upsampling (UpSa (None, None, None, 2 0           decoder_stage0b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_concat (Concaten (None, None, None, 7 0           decoder_stage1_upsampling[0][0]  \n",
      "                                                                 stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_conv (Conv2D)   (None, None, None, 1 884736      decoder_stage1_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_bn (BatchNormal (None, None, None, 1 512         decoder_stage1a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_relu (Activatio (None, None, None, 1 0           decoder_stage1a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_conv (Conv2D)   (None, None, None, 1 147456      decoder_stage1a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_bn (BatchNormal (None, None, None, 1 512         decoder_stage1b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_relu (Activatio (None, None, None, 1 0           decoder_stage1b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_upsampling (UpSa (None, None, None, 1 0           decoder_stage1b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_concat (Concaten (None, None, None, 3 0           decoder_stage2_upsampling[0][0]  \n",
      "                                                                 stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_conv (Conv2D)   (None, None, None, 6 221184      decoder_stage2_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_bn (BatchNormal (None, None, None, 6 256         decoder_stage2a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_relu (Activatio (None, None, None, 6 0           decoder_stage2a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_conv (Conv2D)   (None, None, None, 6 36864       decoder_stage2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_bn (BatchNormal (None, None, None, 6 256         decoder_stage2b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_relu (Activatio (None, None, None, 6 0           decoder_stage2b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_upsampling (UpSa (None, None, None, 6 0           decoder_stage2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_concat (Concaten (None, None, None, 1 0           decoder_stage3_upsampling[0][0]  \n",
      "                                                                 relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_conv (Conv2D)   (None, None, None, 3 36864       decoder_stage3_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_bn (BatchNormal (None, None, None, 3 128         decoder_stage3a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_relu (Activatio (None, None, None, 3 0           decoder_stage3a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_conv (Conv2D)   (None, None, None, 3 9216        decoder_stage3a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_bn (BatchNormal (None, None, None, 3 128         decoder_stage3b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_relu (Activatio (None, None, None, 3 0           decoder_stage3b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_upsampling (UpSa (None, None, None, 3 0           decoder_stage3b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_conv (Conv2D)   (None, None, None, 1 4608        decoder_stage4_upsampling[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_bn (BatchNormal (None, None, None, 1 64          decoder_stage4a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_relu (Activatio (None, None, None, 1 0           decoder_stage4a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_conv (Conv2D)   (None, None, None, 1 2304        decoder_stage4a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_bn (BatchNormal (None, None, None, 1 64          decoder_stage4b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_relu (Activatio (None, None, None, 1 0           decoder_stage4b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv2D)             (None, None, None, 4 580         decoder_stage4b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, None, None, 4 0           final_conv[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 32,561,549\n",
      "Trainable params: 32,513,991\n",
      "Non-trainable params: 47,558\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Start Time for Model 2-Resnet: 2021-07-26 15:29:13.472515\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 15:29:21.196082: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-26 15:29:30.630548: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - ETA: 0s - loss: 0.8444 - iou_score: 0.1558WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0153s vs `on_test_batch_end` time: 0.1164s). Check your callbacks.\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 0.8444 - iou_score: 0.1558 - val_loss: 0.8149 - val_iou_score: 0.1851\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 100s 502ms/step - loss: 0.7783 - iou_score: 0.2217 - val_loss: 0.7720 - val_iou_score: 0.2280\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 100s 502ms/step - loss: 0.7659 - iou_score: 0.2341 - val_loss: 0.7664 - val_iou_score: 0.2336\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 100s 502ms/step - loss: 0.7623 - iou_score: 0.2376 - val_loss: 0.7618 - val_iou_score: 0.2382\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 100s 501ms/step - loss: 0.7606 - iou_score: 0.2394 - val_loss: 0.7608 - val_iou_score: 0.2391\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 100s 501ms/step - loss: 0.7597 - iou_score: 0.2403 - val_loss: 0.7601 - val_iou_score: 0.2399\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 101s 503ms/step - loss: 0.7590 - iou_score: 0.2410 - val_loss: 0.7595 - val_iou_score: 0.2405\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 100s 502ms/step - loss: 0.7588 - iou_score: 0.2411 - val_loss: 0.7592 - val_iou_score: 0.2407\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 100s 501ms/step - loss: 0.7586 - iou_score: 0.2414 - val_loss: 0.7588 - val_iou_score: 0.2411\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 100s 500ms/step - loss: 0.7583 - iou_score: 0.2416 - val_loss: 0.7584 - val_iou_score: 0.2415\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 99s 493ms/step - loss: 0.7582 - iou_score: 0.2418 - val_loss: 0.7587 - val_iou_score: 0.2412\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 100s 502ms/step - loss: 0.7573 - iou_score: 0.2426 - val_loss: 0.7579 - val_iou_score: 0.2420\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 101s 503ms/step - loss: 0.7573 - iou_score: 0.2427 - val_loss: 0.7572 - val_iou_score: 0.2427\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 101s 503ms/step - loss: 0.7564 - iou_score: 0.2436 - val_loss: 0.7570 - val_iou_score: 0.2429\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7563 - iou_score: 0.2437 - val_loss: 0.7587 - val_iou_score: 0.2413\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7579 - iou_score: 0.2421 - val_loss: 0.7578 - val_iou_score: 0.2421\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7563 - iou_score: 0.2437 - val_loss: 0.7571 - val_iou_score: 0.2428\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7574 - iou_score: 0.2427 - val_loss: 0.7577 - val_iou_score: 0.2422\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7565 - iou_score: 0.2435 - val_loss: 0.7586 - val_iou_score: 0.2413\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7574 - iou_score: 0.2426 - val_loss: 0.7576 - val_iou_score: 0.2423\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7570 - iou_score: 0.2430 - val_loss: 0.7587 - val_iou_score: 0.2413\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7572 - iou_score: 0.2428 - val_loss: 0.7580 - val_iou_score: 0.2419\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 100s 500ms/step - loss: 0.7568 - iou_score: 0.2432 - val_loss: 0.7568 - val_iou_score: 0.2431\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7567 - iou_score: 0.2433 - val_loss: 0.7568 - val_iou_score: 0.2431\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 99s 493ms/step - loss: 0.7564 - iou_score: 0.2437 - val_loss: 0.7568 - val_iou_score: 0.2431\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7576 - iou_score: 0.2424 - val_loss: 0.7583 - val_iou_score: 0.2416\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7565 - iou_score: 0.2435 - val_loss: 0.7576 - val_iou_score: 0.2423\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 100s 501ms/step - loss: 0.7568 - iou_score: 0.2432 - val_loss: 0.7568 - val_iou_score: 0.2431\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7567 - iou_score: 0.2433 - val_loss: 0.7582 - val_iou_score: 0.2418\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7565 - iou_score: 0.2435 - val_loss: 0.7574 - val_iou_score: 0.2426\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7549 - iou_score: 0.2451 - val_loss: 0.7579 - val_iou_score: 0.2420\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7556 - iou_score: 0.2445 - val_loss: 0.7571 - val_iou_score: 0.2428\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 100s 501ms/step - loss: 0.7554 - iou_score: 0.2446 - val_loss: 0.7565 - val_iou_score: 0.2434\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7569 - iou_score: 0.2431 - val_loss: 0.7567 - val_iou_score: 0.2432\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7557 - iou_score: 0.2443 - val_loss: 0.7568 - val_iou_score: 0.2431\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7558 - iou_score: 0.2442 - val_loss: 0.7683 - val_iou_score: 0.2316\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7575 - iou_score: 0.2425 - val_loss: 0.7575 - val_iou_score: 0.2424\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7554 - iou_score: 0.2446 - val_loss: 0.7575 - val_iou_score: 0.2425\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7553 - iou_score: 0.2447 - val_loss: 0.7569 - val_iou_score: 0.2430\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7545 - iou_score: 0.2455 - val_loss: 0.7577 - val_iou_score: 0.2422\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 100s 501ms/step - loss: 0.7533 - iou_score: 0.2467 - val_loss: 0.7562 - val_iou_score: 0.2437\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7546 - iou_score: 0.2454 - val_loss: 0.7570 - val_iou_score: 0.2429\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7547 - iou_score: 0.2453 - val_loss: 0.7566 - val_iou_score: 0.2432\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7536 - iou_score: 0.2464 - val_loss: 0.7576 - val_iou_score: 0.2423\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7518 - iou_score: 0.2481 - val_loss: 0.7568 - val_iou_score: 0.2431\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7539 - iou_score: 0.2462 - val_loss: 0.7572 - val_iou_score: 0.2428\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7520 - iou_score: 0.2480 - val_loss: 0.7669 - val_iou_score: 0.2329\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7561 - iou_score: 0.2439 - val_loss: 0.7567 - val_iou_score: 0.2432\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7557 - iou_score: 0.2443 - val_loss: 0.7581 - val_iou_score: 0.2418\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 99s 493ms/step - loss: 0.7559 - iou_score: 0.2441 - val_loss: 0.7569 - val_iou_score: 0.2430\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 99s 493ms/step - loss: 0.7541 - iou_score: 0.2458 - val_loss: 0.7589 - val_iou_score: 0.2410\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 99s 493ms/step - loss: 0.7512 - iou_score: 0.2487 - val_loss: 0.7578 - val_iou_score: 0.2421\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 99s 493ms/step - loss: 0.7501 - iou_score: 0.2499 - val_loss: 0.7581 - val_iou_score: 0.2418\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7481 - iou_score: 0.2519 - val_loss: 0.7576 - val_iou_score: 0.2423\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7476 - iou_score: 0.2524 - val_loss: 0.7576 - val_iou_score: 0.2424\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 0.7436 - iou_score: 0.2564 - val_loss: 0.7591 - val_iou_score: 0.2408\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7398 - iou_score: 0.2601 - val_loss: 0.7588 - val_iou_score: 0.2412\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 99s 493ms/step - loss: 0.7326 - iou_score: 0.2673 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 99s 493ms/step - loss: 0.7348 - iou_score: 0.2652 - val_loss: 0.7591 - val_iou_score: 0.2408\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 98s 492ms/step - loss: 0.7333 - iou_score: 0.2666 - val_loss: 0.7595 - val_iou_score: 0.2405\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 98s 492ms/step - loss: 0.7361 - iou_score: 0.2639 - val_loss: 0.7599 - val_iou_score: 0.2401\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7368 - iou_score: 0.2635 - val_loss: 0.7597 - val_iou_score: 0.2403\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7325 - iou_score: 0.2675 - val_loss: 0.7597 - val_iou_score: 0.2403\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7351 - iou_score: 0.2649 - val_loss: 0.7596 - val_iou_score: 0.2403\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7378 - iou_score: 0.2621 - val_loss: 0.7596 - val_iou_score: 0.2404\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7312 - iou_score: 0.2690 - val_loss: 0.7594 - val_iou_score: 0.2405\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7311 - iou_score: 0.2688 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7302 - iou_score: 0.2698 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7335 - iou_score: 0.2665 - val_loss: 0.7597 - val_iou_score: 0.2403\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7336 - iou_score: 0.2664 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7315 - iou_score: 0.2684 - val_loss: 0.7596 - val_iou_score: 0.2404\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7329 - iou_score: 0.2671 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7298 - iou_score: 0.2707 - val_loss: 0.7596 - val_iou_score: 0.2404\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7387 - iou_score: 0.2612 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7332 - iou_score: 0.2673 - val_loss: 0.7596 - val_iou_score: 0.2403\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7306 - iou_score: 0.2694 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7307 - iou_score: 0.2692 - val_loss: 0.7595 - val_iou_score: 0.2405\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7327 - iou_score: 0.2672 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7337 - iou_score: 0.2662 - val_loss: 0.7596 - val_iou_score: 0.2404\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7298 - iou_score: 0.2702 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7344 - iou_score: 0.2655 - val_loss: 0.7596 - val_iou_score: 0.2404\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7292 - iou_score: 0.2708 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7299 - iou_score: 0.2700 - val_loss: 0.7595 - val_iou_score: 0.2405\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7311 - iou_score: 0.2688 - val_loss: 0.7594 - val_iou_score: 0.2405\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7272 - iou_score: 0.2728 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7335 - iou_score: 0.2664 - val_loss: 0.7595 - val_iou_score: 0.2405\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7312 - iou_score: 0.2687 - val_loss: 0.7595 - val_iou_score: 0.2405\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7324 - iou_score: 0.2675 - val_loss: 0.7595 - val_iou_score: 0.2405\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7357 - iou_score: 0.2643 - val_loss: 0.7596 - val_iou_score: 0.2404\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 99s 493ms/step - loss: 0.7320 - iou_score: 0.2679 - val_loss: 0.7595 - val_iou_score: 0.2405\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 99s 493ms/step - loss: 0.7335 - iou_score: 0.2665 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7265 - iou_score: 0.2734 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7308 - iou_score: 0.2692 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7312 - iou_score: 0.2687 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7310 - iou_score: 0.2689 - val_loss: 0.7596 - val_iou_score: 0.2404\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7307 - iou_score: 0.2692 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7340 - iou_score: 0.2659 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7330 - iou_score: 0.2669 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7311 - iou_score: 0.2691 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 0.7290 - iou_score: 0.2709 - val_loss: 0.7595 - val_iou_score: 0.2404\n",
      "End Time for Model 2-Resnet: 2021-07-26 18:15:32.755050\n",
      "Duration for Model 2-Resnet: 2:46:19.282535\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D\n",
    "from keras.models import Model\n",
    "\n",
    "from tensorflow.keras.utils import get_file\n",
    "###Model 2\n",
    "BACKBONE2 =  'resnet50'\n",
    "preprocess_input2 = sm.get_preprocessing(BACKBONE2)\n",
    "\n",
    "# preprocess input\n",
    "X_train2 = preprocess_input2(X_train)\n",
    "X_test2 = preprocess_input2(X_test)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('./best_model2_100.h5', save_weights_only=True, save_best_only=True, mode='min'),\n",
    "    keras.callbacks.ReduceLROnPlateau(),\n",
    "]\n",
    "\n",
    "random_state=0\n",
    "# define model\n",
    "model2_100 = sm.Unet(BACKBONE2, encoder_weights=None, classes=n_classes, activation=activation)\n",
    "\n",
    "# compile keras model with defined optimizer, loss and metrics\n",
    "model2_100.compile(optimizer=optim, loss=sm.losses.JaccardLoss(), metrics=sm.metrics.IOUScore())\n",
    "print(model2_100.summary())\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "start_time_resnet = datetime.now()\n",
    "print('Start Time for Model 2-Resnet: {}'.format(start_time_resnet))\n",
    "\n",
    "\n",
    "history2_100=model2_100.fit(X_train2, \n",
    "          y_train_cat,\n",
    "          batch_size=32, \n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test2, y_test_cat), callbacks=callbacks)\n",
    "\n",
    "end_time_resnet = datetime.now()\n",
    "print('End Time for Model 2-Resnet: {}'.format(end_time_resnet))\n",
    "print('Duration for Model 2-Resnet: {}'.format(end_time_resnet - start_time_resnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a77f7473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 18:15:41.444257: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet50_100epochs.tf/assets\n"
     ]
    }
   ],
   "source": [
    "model2_100.save('resnet50_100epochs.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddf8076a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n",
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, None, None, 3 864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, None, None, 3 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, None, None, 3 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, None, None, 3 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, None, None, 3 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, None, None, 3 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, None, None, 1 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, None, None, 1 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, None, None, 9 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, None, None, 9 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, None, None, 9 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, None, None, 9 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, None, None, 9 864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, None, None, 9 384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, None, None, 9 0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, None, None, 2 2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, None, None, 2 96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, None, None, 1 3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, None, None, 1 576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, None, None, 1 0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, None, None, 1 1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, None, None, 1 576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, None, None, 1 0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, None, None, 2 3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, None, None, 2 96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, None, None, 2 0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, None, None, 1 3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, None, None, 1 576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, None, None, 1 0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, None, None, 1 0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, None, None, 1 1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, None, None, 1 576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, None, None, 1 0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, None, None, 3 4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, None, None, 3 128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, None, None, 1 6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, None, None, 1 768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, None, None, 1 0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, None, None, 1 1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, None, None, 1 768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, None, None, 1 0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, None, None, 3 6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, None, None, 3 128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, None, None, 3 0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, None, None, 1 6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, None, None, 1 768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, None, None, 1 0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, None, None, 1 1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, None, None, 1 768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, None, None, 1 0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, None, None, 3 6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, None, None, 3 128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, None, None, 3 0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, None, None, 1 6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, None, None, 1 768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, None, None, 1 0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, None, None, 1 0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, None, None, 1 1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, None, None, 1 768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, None, None, 1 0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, None, None, 6 12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, None, None, 6 256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, None, None, 3 24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, None, None, 3 1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, None, None, 3 0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, None, None, 3 3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, None, None, 3 1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, None, None, 3 0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, None, None, 6 24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, None, None, 6 256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, None, None, 6 0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, None, None, 3 24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, None, None, 3 1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, None, None, 3 0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, None, None, 3 3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, None, None, 3 1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, None, None, 3 0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, None, None, 6 24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, None, None, 6 256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, None, None, 6 0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, None, None, 3 24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, None, None, 3 1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, None, None, 3 0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, None, None, 3 3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, None, None, 3 1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, None, None, 3 0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, None, None, 6 24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, None, None, 6 256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, None, None, 6 0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, None, None, 3 24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, None, None, 3 1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, None, None, 3 0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, None, None, 3 3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, None, None, 3 1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, None, None, 3 0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, None, None, 9 36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, None, None, 9 384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, None, None, 5 55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, None, None, 5 2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, None, None, 5 0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, None, None, 5 5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, None, None, 5 2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, None, None, 5 0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, None, None, 9 55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, None, None, 9 384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, None, None, 9 0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, None, None, 5 55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, None, None, 5 2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, None, None, 5 0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, None, None, 5 5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, None, None, 5 2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, None, None, 5 0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, None, None, 9 55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, None, None, 9 384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, None, None, 9 0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, None, None, 5 55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, None, None, 5 2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, None, None, 5 0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, None, None, 5 0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, None, None, 5 5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, None, None, 5 2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, None, None, 5 0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, None, None, 1 92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, None, None, 1 640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, None, None, 9 153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, None, None, 9 3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, None, None, 9 0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, None, None, 9 8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, None, None, 9 3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, None, None, 9 0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, None, None, 1 153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, None, None, 1 640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, None, None, 1 0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, None, None, 9 153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, None, None, 9 3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, None, None, 9 0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, None, None, 9 8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, None, None, 9 3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, None, None, 9 0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, None, None, 1 153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, None, None, 1 640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, None, None, 1 0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, None, None, 9 153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, None, None, 9 3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, None, None, 9 0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, None, None, 9 8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, None, None, 9 3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, None, None, 9 0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, None, None, 3 307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, None, None, 3 1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, None, None, 1 409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, None, None, 1 5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, None, None, 1 0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_upsampling (UpSa (None, None, None, 1 0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_concat (Concaten (None, None, None, 1 0           decoder_stage0_upsampling[0][0]  \n",
      "                                                                 block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_conv (Conv2D)   (None, None, None, 2 4276224     decoder_stage0_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_relu (Activatio (None, None, None, 2 0           decoder_stage0a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_conv (Conv2D)   (None, None, None, 2 589824      decoder_stage0a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_relu (Activatio (None, None, None, 2 0           decoder_stage0b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_upsampling (UpSa (None, None, None, 2 0           decoder_stage0b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_concat (Concaten (None, None, None, 4 0           decoder_stage1_upsampling[0][0]  \n",
      "                                                                 block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_conv (Conv2D)   (None, None, None, 1 516096      decoder_stage1_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_bn (BatchNormal (None, None, None, 1 512         decoder_stage1a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_relu (Activatio (None, None, None, 1 0           decoder_stage1a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_conv (Conv2D)   (None, None, None, 1 147456      decoder_stage1a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_bn (BatchNormal (None, None, None, 1 512         decoder_stage1b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_relu (Activatio (None, None, None, 1 0           decoder_stage1b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_upsampling (UpSa (None, None, None, 1 0           decoder_stage1b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_concat (Concaten (None, None, None, 2 0           decoder_stage2_upsampling[0][0]  \n",
      "                                                                 block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_conv (Conv2D)   (None, None, None, 6 156672      decoder_stage2_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_bn (BatchNormal (None, None, None, 6 256         decoder_stage2a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_relu (Activatio (None, None, None, 6 0           decoder_stage2a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_conv (Conv2D)   (None, None, None, 6 36864       decoder_stage2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_bn (BatchNormal (None, None, None, 6 256         decoder_stage2b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_relu (Activatio (None, None, None, 6 0           decoder_stage2b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_upsampling (UpSa (None, None, None, 6 0           decoder_stage2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_concat (Concaten (None, None, None, 1 0           decoder_stage3_upsampling[0][0]  \n",
      "                                                                 block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_conv (Conv2D)   (None, None, None, 3 46080       decoder_stage3_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_bn (BatchNormal (None, None, None, 3 128         decoder_stage3a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_relu (Activatio (None, None, None, 3 0           decoder_stage3a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_conv (Conv2D)   (None, None, None, 3 9216        decoder_stage3a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_bn (BatchNormal (None, None, None, 3 128         decoder_stage3b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_relu (Activatio (None, None, None, 3 0           decoder_stage3b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_upsampling (UpSa (None, None, None, 3 0           decoder_stage3b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_conv (Conv2D)   (None, None, None, 1 4608        decoder_stage4_upsampling[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_bn (BatchNormal (None, None, None, 1 64          decoder_stage4a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_relu (Activatio (None, None, None, 1 0           decoder_stage4a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_conv (Conv2D)   (None, None, None, 1 2304        decoder_stage4a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_bn (BatchNormal (None, None, None, 1 64          decoder_stage4b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_relu (Activatio (None, None, None, 1 0           decoder_stage4b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv2D)             (None, None, None, 4 580         decoder_stage4b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, None, None, 4 0           final_conv[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 8,047,876\n",
      "Trainable params: 8,011,780\n",
      "Non-trainable params: 36,096\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Start Time for Model 3-Mobilenetv2: 2021-07-26 18:16:00.965259\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9251 - iou_score: 0.0749WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0124s vs `on_test_batch_end` time: 0.0684s). Check your callbacks.\n",
      "200/200 [==============================] - 64s 320ms/step - loss: 0.9251 - iou_score: 0.0749 - val_loss: 0.9355 - val_iou_score: 0.0645\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 61s 303ms/step - loss: 0.9251 - iou_score: 0.0749 - val_loss: 0.9366 - val_iou_score: 0.0634\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 61s 306ms/step - loss: 0.9251 - iou_score: 0.0749 - val_loss: 0.9354 - val_iou_score: 0.0646\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9345 - val_iou_score: 0.0655\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 61s 307ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9332 - val_iou_score: 0.0669\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9251 - iou_score: 0.0749 - val_loss: 0.9311 - val_iou_score: 0.0690\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 62s 308ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9287 - val_iou_score: 0.0713\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9254 - val_iou_score: 0.0746\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 62s 308ms/step - loss: 0.9251 - iou_score: 0.0749 - val_loss: 0.9217 - val_iou_score: 0.0784\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 61s 306ms/step - loss: 0.9251 - iou_score: 0.0749 - val_loss: 0.9175 - val_iou_score: 0.0825\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 62s 308ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9161 - val_iou_score: 0.0839\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 61s 306ms/step - loss: 0.9251 - iou_score: 0.0749 - val_loss: 0.9153 - val_iou_score: 0.0847\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 62s 308ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9152 - val_iou_score: 0.0848\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9251 - iou_score: 0.0749 - val_loss: 0.9151 - val_iou_score: 0.0850\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9155 - val_iou_score: 0.0846\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 60s 302ms/step - loss: 0.9251 - iou_score: 0.0749 - val_loss: 0.9151 - val_iou_score: 0.0850\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 61s 303ms/step - loss: 0.9251 - iou_score: 0.0749 - val_loss: 0.9151 - val_iou_score: 0.0850\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 60s 302ms/step - loss: 0.9251 - iou_score: 0.0749 - val_loss: 0.9158 - val_iou_score: 0.0842\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 61s 304ms/step - loss: 0.9250 - iou_score: 0.0749 - val_loss: 0.9160 - val_iou_score: 0.0840\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 61s 303ms/step - loss: 0.9251 - iou_score: 0.0750 - val_loss: 0.9162 - val_iou_score: 0.0838\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9167 - val_iou_score: 0.0833\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 61s 303ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9173 - val_iou_score: 0.0827\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 61s 304ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9180 - val_iou_score: 0.0820\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 60s 302ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9186 - val_iou_score: 0.0815\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 61s 306ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9189 - val_iou_score: 0.0811\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 61s 304ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9194 - val_iou_score: 0.0806\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9201 - val_iou_score: 0.0800\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 61s 303ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9206 - val_iou_score: 0.0795\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9210 - val_iou_score: 0.0791\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 61s 303ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9213 - val_iou_score: 0.0788\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9218 - val_iou_score: 0.0783\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 61s 304ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9221 - val_iou_score: 0.0779\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 61s 306ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9223 - val_iou_score: 0.0777\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 61s 303ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9226 - val_iou_score: 0.0775\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9228 - val_iou_score: 0.0773\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 61s 303ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9231 - val_iou_score: 0.0770\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9234 - val_iou_score: 0.0767\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 61s 303ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9236 - val_iou_score: 0.0765\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9237 - val_iou_score: 0.0763\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 60s 302ms/step - loss: 0.9251 - iou_score: 0.0749 - val_loss: 0.9238 - val_iou_score: 0.0763\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 61s 304ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9239 - val_iou_score: 0.0761\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 60s 302ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9240 - val_iou_score: 0.0760\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9241 - val_iou_score: 0.0759\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 60s 302ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9242 - val_iou_score: 0.0758\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9243 - val_iou_score: 0.0758\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 61s 303ms/step - loss: 0.9250 - iou_score: 0.0749 - val_loss: 0.9244 - val_iou_score: 0.0757\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9244 - val_iou_score: 0.0756\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 61s 303ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9245 - val_iou_score: 0.0756\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9245 - val_iou_score: 0.0756\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 61s 303ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9245 - val_iou_score: 0.0756\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9251 - iou_score: 0.0749 - val_loss: 0.9245 - val_iou_score: 0.0755\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 61s 303ms/step - loss: 0.9250 - iou_score: 0.0750 - val_loss: 0.9245 - val_iou_score: 0.0755\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 0.9251 - iou_score: 0.0749 - val_loss: 0.9245 - val_iou_score: 0.0755\n",
      "Epoch 54/100\n",
      " 83/200 [===========>..................] - ETA: 32s - loss: 0.9250 - iou_score: 0.0750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2403/2336202622.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m           validation_data=(X_test3, y_test_cat), callbacks=callbacks)\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mend_time_resnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D\n",
    "from keras.models import Model\n",
    "\n",
    "from tensorflow.keras.utils import get_file\n",
    "###Model 3\n",
    "BACKBONE3 =  'mobilenetv2'\n",
    "preprocess_input3 = sm.get_preprocessing(BACKBONE3)\n",
    "\n",
    "# preprocess input\n",
    "X_train3 = preprocess_input3(X_train)\n",
    "X_test3 = preprocess_input3(X_test)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('./best_model3_100.h5', save_weights_only=True, save_best_only=True, mode='min'),\n",
    "    keras.callbacks.ReduceLROnPlateau(),\n",
    "]\n",
    "\n",
    "random_state=0\n",
    "# define model\n",
    "model3_100 = sm.Unet(BACKBONE3, encoder_weights='imagenet', classes=n_classes, activation=activation)\n",
    "\n",
    "# compile keras model with defined optimizer, loss and metrics\n",
    "model3_100.compile(optimizer=optim, loss=sm.losses.JaccardLoss(), metrics=sm.metrics.IOUScore())\n",
    "print(model3_100.summary())\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "start_time_resnet = datetime.now()\n",
    "print('Start Time for Model 3-Mobilenetv2: {}'.format(start_time_resnet))\n",
    "\n",
    "\n",
    "history3_100=model3_100.fit(X_train3, \n",
    "          y_train_cat,\n",
    "          batch_size=32, \n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test3, y_test_cat), callbacks=callbacks)\n",
    "\n",
    "end_time_resnet = datetime.now()\n",
    "print('End Time for Model 3-Mobilenetv2: {}'.format(end_time_resnet))\n",
    "print('Duration for Model 3-Mobilenetv2: {}'.format(end_time_resnet - start_time_resnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af5b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3_100.save('mobilenetv2_100epochs.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7392c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 2s 0us/step\n",
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, None, None, 6 1792        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, None, None, 6 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, None, None, 6 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, None, None, 1 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, None, None, 1 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, None, None, 2 295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, None, None, 2 590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, None, None, 2 590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, None, None, 2 590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, None, None, 5 1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, None, None, 5 2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, None, None, 5 2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, None, None, 5 2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, None, None, 5 0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, None, None, 5 2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, None, None, 5 2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, None, None, 5 2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, None, None, 5 2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, None, None, 5 0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_block1_conv (Conv2D)     (None, None, None, 5 2359296     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_block1_bn (BatchNormaliz (None, None, None, 5 2048        center_block1_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_block1_relu (Activation) (None, None, None, 5 0           center_block1_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "center_block2_conv (Conv2D)     (None, None, None, 5 2359296     center_block1_relu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_block2_bn (BatchNormaliz (None, None, None, 5 2048        center_block2_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_block2_relu (Activation) (None, None, None, 5 0           center_block2_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_upsampling (UpSa (None, None, None, 5 0           center_block2_relu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_concat (Concaten (None, None, None, 1 0           decoder_stage0_upsampling[0][0]  \n",
      "                                                                 block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_conv (Conv2D)   (None, None, None, 2 2359296     decoder_stage0_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_relu (Activatio (None, None, None, 2 0           decoder_stage0a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_conv (Conv2D)   (None, None, None, 2 589824      decoder_stage0a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_relu (Activatio (None, None, None, 2 0           decoder_stage0b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_upsampling (UpSa (None, None, None, 2 0           decoder_stage0b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_concat (Concaten (None, None, None, 7 0           decoder_stage1_upsampling[0][0]  \n",
      "                                                                 block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_conv (Conv2D)   (None, None, None, 1 884736      decoder_stage1_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_bn (BatchNormal (None, None, None, 1 512         decoder_stage1a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_relu (Activatio (None, None, None, 1 0           decoder_stage1a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_conv (Conv2D)   (None, None, None, 1 147456      decoder_stage1a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_bn (BatchNormal (None, None, None, 1 512         decoder_stage1b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_relu (Activatio (None, None, None, 1 0           decoder_stage1b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_upsampling (UpSa (None, None, None, 1 0           decoder_stage1b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_concat (Concaten (None, None, None, 3 0           decoder_stage2_upsampling[0][0]  \n",
      "                                                                 block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_conv (Conv2D)   (None, None, None, 6 221184      decoder_stage2_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_bn (BatchNormal (None, None, None, 6 256         decoder_stage2a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_relu (Activatio (None, None, None, 6 0           decoder_stage2a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_conv (Conv2D)   (None, None, None, 6 36864       decoder_stage2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_bn (BatchNormal (None, None, None, 6 256         decoder_stage2b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_relu (Activatio (None, None, None, 6 0           decoder_stage2b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_upsampling (UpSa (None, None, None, 6 0           decoder_stage2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_concat (Concaten (None, None, None, 1 0           decoder_stage3_upsampling[0][0]  \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_conv (Conv2D)   (None, None, None, 3 55296       decoder_stage3_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_bn (BatchNormal (None, None, None, 3 128         decoder_stage3a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_relu (Activatio (None, None, None, 3 0           decoder_stage3a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_conv (Conv2D)   (None, None, None, 3 9216        decoder_stage3a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_bn (BatchNormal (None, None, None, 3 128         decoder_stage3b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_relu (Activatio (None, None, None, 3 0           decoder_stage3b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_upsampling (UpSa (None, None, None, 3 0           decoder_stage3b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_conv (Conv2D)   (None, None, None, 1 4608        decoder_stage4_upsampling[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_bn (BatchNormal (None, None, None, 1 64          decoder_stage4a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_relu (Activatio (None, None, None, 1 0           decoder_stage4a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_conv (Conv2D)   (None, None, None, 1 2304        decoder_stage4a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_bn (BatchNormal (None, None, None, 1 64          decoder_stage4b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_relu (Activatio (None, None, None, 1 0           decoder_stage4b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv2D)             (None, None, None, 4 580         decoder_stage4b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, None, None, 4 0           final_conv[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 29,062,404\n",
      "Trainable params: 29,058,372\n",
      "Non-trainable params: 4,032\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Start Time for Model 1-Resnet: 2021-07-26 19:52:57.973978\n",
      "Epoch 1/100\n",
      "  2/100 [..............................] - ETA: 44s - loss: 0.9369 - iou_score: 0.0631WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3147s vs `on_train_batch_end` time: 0.5926s). Check your callbacks.\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9367 - iou_score: 0.0633WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0154s vs `on_test_batch_end` time: 0.2614s). Check your callbacks.\n",
      "100/100 [==============================] - 113s 1s/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9432 - val_iou_score: 0.0569\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 100s 1s/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9346 - val_iou_score: 0.0655\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9383 - val_iou_score: 0.0618\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9379 - val_iou_score: 0.0622\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9370 - val_iou_score: 0.0632\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9365 - val_iou_score: 0.0637\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0638\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0638\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 99s 992ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0638\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 99s 994ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0639\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0639\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0639\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0639\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0639\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0639\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0639\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0639\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0639\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0639\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 99s 994ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0639\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0639\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0639\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0639\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 99s 992ms/step - loss: 0.9367 - iou_score: 0.0633 - val_loss: 0.9363 - val_iou_score: 0.0639\n",
      "Epoch 25/100\n",
      " 25/100 [======>.......................] - ETA: 1:05 - loss: 0.9364 - iou_score: 0.0636"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D\n",
    "from keras.models import Model\n",
    "\n",
    "from tensorflow.keras.utils import get_file\n",
    "###Model 1\n",
    "BACKBONE1 =  'vgg19'\n",
    "preprocess_input1 = sm.get_preprocessing(BACKBONE1)\n",
    "\n",
    "# preprocess input\n",
    "X_train1 = preprocess_input1(X_train)\n",
    "X_test1 = preprocess_input1(X_test)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('./best_model1_2.h5', save_weights_only=True, save_best_only=True, mode='min'),\n",
    "    keras.callbacks.ReduceLROnPlateau(),\n",
    "]\n",
    "\n",
    "random_state=0\n",
    "# define model\n",
    "model1_2 = sm.Unet(BACKBONE1, encoder_weights='imagenet', classes=n_classes, activation=activation)\n",
    "\n",
    "# compile keras model with defined optimizer, loss and metrics\n",
    "model1_2.compile(optimizer=optim, loss=sm.losses.JaccardLoss(), metrics=sm.metrics.IOUScore())\n",
    "print(model1_2.summary())\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "start_time_resnet = datetime.now()\n",
    "print('Start Time for Model 1-Resnet: {}'.format(start_time_resnet))\n",
    "\n",
    "\n",
    "history1_2=model1_2.fit(X_train1, \n",
    "          y_train_cat,\n",
    "          batch_size=64, \n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test1, y_test_cat), callbacks=callbacks)\n",
    "\n",
    "end_time_resnet = datetime.now()\n",
    "print('End Time for Model 1-Resnet: {}'.format(end_time_resnet))\n",
    "print('Duration for Model 1-Resnet: {}'.format(end_time_resnet - start_time_resnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be68315",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_2.save('unet_vgg19_100epochs.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f061386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
